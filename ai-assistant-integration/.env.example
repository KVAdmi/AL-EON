# ============================================
# AL-EON AI Assistant - Configuración
# ============================================

# --- PROVEEDOR LLM (Elige UNO) ---
# Opción 1: Anthropic Claude (Recomendado - Como GitHub Copilot)
ANTHROPIC_API_KEY=sk-ant-xxxxx

# Opción 2: OpenAI GPT-4
OPENAI_API_KEY=sk-xxxxx

# Opción 3: Google Gemini (Gratis tier disponible)
GEMINI_API_KEY=xxxxx

# Opción 4: Mistral AI
MISTRAL_API_KEY=xxxxx

# Opción 5: Ollama (Local - No requiere API key)
OLLAMA_BASE_URL=http://localhost:11434

# --- PROVEEDOR ACTIVO ---
LLM_PROVIDER=anthropic  # anthropic | openai | gemini | mistral | ollama

# --- MODELO ESPECÍFICO ---
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# OpenAI: gpt-4-turbo-preview, gpt-4o, gpt-3.5-turbo
# Gemini: gemini-1.5-pro, gemini-1.5-flash
# Mistral: mistral-large-latest, codestral-latest
# Ollama: deepseek-coder:33b, codellama:34b, mixtral:8x7b
LLM_MODEL=claude-3-5-sonnet-20241022

# --- GITHUB ---
GITHUB_TOKEN=ghp_xxxxx
GITHUB_OWNER=KVAdmi
GITHUB_REPO=AL-EON

# --- BASE DE DATOS VECTORIAL ---
# ChromaDB (Local - default)
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Pinecone (Opcional - Cloud)
# PINECONE_API_KEY=xxxxx
# PINECONE_ENVIRONMENT=us-east-1-aws
# PINECONE_INDEX=aleon-code

# --- EMBEDDINGS ---
EMBEDDING_PROVIDER=openai  # openai | local
EMBEDDING_MODEL=text-embedding-3-small

# --- SERVIDOR ---
PORT=3001
NODE_ENV=development

# --- OPCIONES AVANZADAS ---
MAX_TOKENS=4096
TEMPERATURE=0.2
TOP_K_RESULTS=5
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
